{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b123b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import pandas as pd\n",
    "import nltk\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9189e87",
   "metadata": {},
   "source": [
    "Now we want to preprocess the tweets accordingly to their languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9b176f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the languages we want to preprocess\n",
    "lang_list = ['en', 'es', 'pt']\n",
    "\n",
    "# define what each iso-639 code means\n",
    "lang_dict = {\n",
    "    'en': 'english',\n",
    "    'es': 'spanish',\n",
    "    'pt': 'portugese'\n",
    "}\n",
    "\n",
    "clean_data_dir = './clean_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00faa799",
   "metadata": {},
   "source": [
    "We will preprocess English first. Let's import the csv file into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c348ac0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>clean_tweets</th>\n",
       "      <th>prediction</th>\n",
       "      <th>language</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>I felt my first flash of violence at some fool...</td>\n",
       "      <td>('en', 0.9772645831108093)</td>\n",
       "      <td>en</td>\n",
       "      <td>0.977265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Ladies drink and get in free till</td>\n",
       "      <td>('en', 0.6527988910675049)</td>\n",
       "      <td>en</td>\n",
       "      <td>0.652799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>Watching Miranda On bbc mermhart u r HILARIOUS</td>\n",
       "      <td>('en', 0.5819909572601318)</td>\n",
       "      <td>en</td>\n",
       "      <td>0.581991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Shopping  Kohls httptcoIZkQHT</td>\n",
       "      <td>('en', 0.5320528745651245)</td>\n",
       "      <td>en</td>\n",
       "      <td>0.532053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>Dennycrowe all over twitter because you and yo...</td>\n",
       "      <td>('en', 0.768022358417511)</td>\n",
       "      <td>en</td>\n",
       "      <td>0.768022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>10492</td>\n",
       "      <td>Another Cardigan Records Hopscotch Day Party i...</td>\n",
       "      <td>('en', 0.920673131942749)</td>\n",
       "      <td>en</td>\n",
       "      <td>0.920673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4308</th>\n",
       "      <td>10493</td>\n",
       "      <td>Im at Hempstead Hair World in Elmont NY httpst...</td>\n",
       "      <td>('en', 0.5241799354553223)</td>\n",
       "      <td>en</td>\n",
       "      <td>0.524180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4309</th>\n",
       "      <td>10494</td>\n",
       "      <td>Bachelorette   Laurita Winery httpstcoBsIIFmdGz</td>\n",
       "      <td>('en', 0.6609522104263306)</td>\n",
       "      <td>en</td>\n",
       "      <td>0.660952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4310</th>\n",
       "      <td>10496</td>\n",
       "      <td>This job might be a great fit for you Sr Infor...</td>\n",
       "      <td>('en', 0.6981475949287415)</td>\n",
       "      <td>en</td>\n",
       "      <td>0.698148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4311</th>\n",
       "      <td>10497</td>\n",
       "      <td>Im at PiazzaAvym in Canik Samsun w mertarmann ...</td>\n",
       "      <td>('en', 0.6175498366355896)</td>\n",
       "      <td>en</td>\n",
       "      <td>0.617550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4312 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                       clean_tweets  \\\n",
       "0              3  I felt my first flash of violence at some fool...   \n",
       "1              4                 Ladies drink and get in free till    \n",
       "2              7    Watching Miranda On bbc mermhart u r HILARIOUS    \n",
       "3              9                      Shopping  Kohls httptcoIZkQHT   \n",
       "4             16  Dennycrowe all over twitter because you and yo...   \n",
       "...          ...                                                ...   \n",
       "4307       10492  Another Cardigan Records Hopscotch Day Party i...   \n",
       "4308       10493  Im at Hempstead Hair World in Elmont NY httpst...   \n",
       "4309       10494    Bachelorette   Laurita Winery httpstcoBsIIFmdGz   \n",
       "4310       10496  This job might be a great fit for you Sr Infor...   \n",
       "4311       10497  Im at PiazzaAvym in Canik Samsun w mertarmann ...   \n",
       "\n",
       "                      prediction language  confidence  \n",
       "0     ('en', 0.9772645831108093)       en    0.977265  \n",
       "1     ('en', 0.6527988910675049)       en    0.652799  \n",
       "2     ('en', 0.5819909572601318)       en    0.581991  \n",
       "3     ('en', 0.5320528745651245)       en    0.532053  \n",
       "4      ('en', 0.768022358417511)       en    0.768022  \n",
       "...                          ...      ...         ...  \n",
       "4307   ('en', 0.920673131942749)       en    0.920673  \n",
       "4308  ('en', 0.5241799354553223)       en    0.524180  \n",
       "4309  ('en', 0.6609522104263306)       en    0.660952  \n",
       "4310  ('en', 0.6981475949287415)       en    0.698148  \n",
       "4311  ('en', 0.6175498366355896)       en    0.617550  \n",
       "\n",
       "[4312 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldir = os.path.join(clean_data_dir, 'en' + '.csv')   \n",
    "\n",
    "df_eng = pd.read_csv(fulldir)\n",
    "df_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6648bb",
   "metadata": {},
   "source": [
    "Since we just want the `clean_tweets` we can just omit other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c01288a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I felt my first flash of violence at some fool...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ladies drink and get in free till</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Watching Miranda On bbc mermhart u r HILARIOUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shopping  Kohls httptcoIZkQHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dennycrowe all over twitter because you and yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>Another Cardigan Records Hopscotch Day Party i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4308</th>\n",
       "      <td>Im at Hempstead Hair World in Elmont NY httpst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4309</th>\n",
       "      <td>Bachelorette   Laurita Winery httpstcoBsIIFmdGz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4310</th>\n",
       "      <td>This job might be a great fit for you Sr Infor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4311</th>\n",
       "      <td>Im at PiazzaAvym in Canik Samsun w mertarmann ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4312 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           clean_tweets\n",
       "0     I felt my first flash of violence at some fool...\n",
       "1                    Ladies drink and get in free till \n",
       "2       Watching Miranda On bbc mermhart u r HILARIOUS \n",
       "3                         Shopping  Kohls httptcoIZkQHT\n",
       "4     Dennycrowe all over twitter because you and yo...\n",
       "...                                                 ...\n",
       "4307  Another Cardigan Records Hopscotch Day Party i...\n",
       "4308  Im at Hempstead Hair World in Elmont NY httpst...\n",
       "4309    Bachelorette   Laurita Winery httpstcoBsIIFmdGz\n",
       "4310  This job might be a great fit for you Sr Infor...\n",
       "4311  Im at PiazzaAvym in Canik Samsun w mertarmann ...\n",
       "\n",
       "[4312 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eng_clean_tweets = df_eng[['clean_tweets']]\n",
    "df_eng_clean_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dec9a2",
   "metadata": {},
   "source": [
    "Firstly, we want to lowercase everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec361363",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweets</th>\n",
       "      <th>lowercase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I felt my first flash of violence at some fool...</td>\n",
       "      <td>i felt my first flash of violence at some fool...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ladies drink and get in free till</td>\n",
       "      <td>ladies drink and get in free till</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Watching Miranda On bbc mermhart u r HILARIOUS</td>\n",
       "      <td>watching miranda on bbc mermhart u r hilarious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shopping  Kohls httptcoIZkQHT</td>\n",
       "      <td>shopping  kohls httptcoizkqht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dennycrowe all over twitter because you and yo...</td>\n",
       "      <td>dennycrowe all over twitter because you and yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>Another Cardigan Records Hopscotch Day Party i...</td>\n",
       "      <td>another cardigan records hopscotch day party i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4308</th>\n",
       "      <td>Im at Hempstead Hair World in Elmont NY httpst...</td>\n",
       "      <td>im at hempstead hair world in elmont ny httpst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4309</th>\n",
       "      <td>Bachelorette   Laurita Winery httpstcoBsIIFmdGz</td>\n",
       "      <td>bachelorette   laurita winery httpstcobsiifmdgz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4310</th>\n",
       "      <td>This job might be a great fit for you Sr Infor...</td>\n",
       "      <td>this job might be a great fit for you sr infor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4311</th>\n",
       "      <td>Im at PiazzaAvym in Canik Samsun w mertarmann ...</td>\n",
       "      <td>im at piazzaavym in canik samsun w mertarmann ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4312 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           clean_tweets  \\\n",
       "0     I felt my first flash of violence at some fool...   \n",
       "1                    Ladies drink and get in free till    \n",
       "2       Watching Miranda On bbc mermhart u r HILARIOUS    \n",
       "3                         Shopping  Kohls httptcoIZkQHT   \n",
       "4     Dennycrowe all over twitter because you and yo...   \n",
       "...                                                 ...   \n",
       "4307  Another Cardigan Records Hopscotch Day Party i...   \n",
       "4308  Im at Hempstead Hair World in Elmont NY httpst...   \n",
       "4309    Bachelorette   Laurita Winery httpstcoBsIIFmdGz   \n",
       "4310  This job might be a great fit for you Sr Infor...   \n",
       "4311  Im at PiazzaAvym in Canik Samsun w mertarmann ...   \n",
       "\n",
       "                                              lowercase  \n",
       "0     i felt my first flash of violence at some fool...  \n",
       "1                    ladies drink and get in free till   \n",
       "2       watching miranda on bbc mermhart u r hilarious   \n",
       "3                         shopping  kohls httptcoizkqht  \n",
       "4     dennycrowe all over twitter because you and yo...  \n",
       "...                                                 ...  \n",
       "4307  another cardigan records hopscotch day party i...  \n",
       "4308  im at hempstead hair world in elmont ny httpst...  \n",
       "4309    bachelorette   laurita winery httpstcobsiifmdgz  \n",
       "4310  this job might be a great fit for you sr infor...  \n",
       "4311  im at piazzaavym in canik samsun w mertarmann ...  \n",
       "\n",
       "[4312 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eng_clean_tweets['lowercase'] = df_eng_clean_tweets['clean_tweets'].apply(lambda x: x.lower())\n",
    "df_eng_clean_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50663193",
   "metadata": {},
   "source": [
    "Then we remove the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd985030",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/bingyuyap/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweets</th>\n",
       "      <th>lowercase</th>\n",
       "      <th>stopwords_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I felt my first flash of violence at some fool...</td>\n",
       "      <td>i felt my first flash of violence at some fool...</td>\n",
       "      <td>felt first flash violence fool bumped pity fool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ladies drink and get in free till</td>\n",
       "      <td>ladies drink and get in free till</td>\n",
       "      <td>ladies drink get free till</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Watching Miranda On bbc mermhart u r HILARIOUS</td>\n",
       "      <td>watching miranda on bbc mermhart u r hilarious</td>\n",
       "      <td>watching miranda bbc mermhart u r hilarious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shopping  Kohls httptcoIZkQHT</td>\n",
       "      <td>shopping  kohls httptcoizkqht</td>\n",
       "      <td>shopping kohls httptcoizkqht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dennycrowe all over twitter because you and yo...</td>\n",
       "      <td>dennycrowe all over twitter because you and yo...</td>\n",
       "      <td>dennycrowe twitter friends cant stick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>Another Cardigan Records Hopscotch Day Party i...</td>\n",
       "      <td>another cardigan records hopscotch day party i...</td>\n",
       "      <td>another cardigan records hopscotch day party b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4308</th>\n",
       "      <td>Im at Hempstead Hair World in Elmont NY httpst...</td>\n",
       "      <td>im at hempstead hair world in elmont ny httpst...</td>\n",
       "      <td>im hempstead hair world elmont ny httpstcohvyg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4309</th>\n",
       "      <td>Bachelorette   Laurita Winery httpstcoBsIIFmdGz</td>\n",
       "      <td>bachelorette   laurita winery httpstcobsiifmdgz</td>\n",
       "      <td>bachelorette laurita winery httpstcobsiifmdgz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4310</th>\n",
       "      <td>This job might be a great fit for you Sr Infor...</td>\n",
       "      <td>this job might be a great fit for you sr infor...</td>\n",
       "      <td>job might great fit sr information architect s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4311</th>\n",
       "      <td>Im at PiazzaAvym in Canik Samsun w mertarmann ...</td>\n",
       "      <td>im at piazzaavym in canik samsun w mertarmann ...</td>\n",
       "      <td>im piazzaavym canik samsun w mertarmann debeab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4312 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           clean_tweets  \\\n",
       "0     I felt my first flash of violence at some fool...   \n",
       "1                    Ladies drink and get in free till    \n",
       "2       Watching Miranda On bbc mermhart u r HILARIOUS    \n",
       "3                         Shopping  Kohls httptcoIZkQHT   \n",
       "4     Dennycrowe all over twitter because you and yo...   \n",
       "...                                                 ...   \n",
       "4307  Another Cardigan Records Hopscotch Day Party i...   \n",
       "4308  Im at Hempstead Hair World in Elmont NY httpst...   \n",
       "4309    Bachelorette   Laurita Winery httpstcoBsIIFmdGz   \n",
       "4310  This job might be a great fit for you Sr Infor...   \n",
       "4311  Im at PiazzaAvym in Canik Samsun w mertarmann ...   \n",
       "\n",
       "                                              lowercase  \\\n",
       "0     i felt my first flash of violence at some fool...   \n",
       "1                    ladies drink and get in free till    \n",
       "2       watching miranda on bbc mermhart u r hilarious    \n",
       "3                         shopping  kohls httptcoizkqht   \n",
       "4     dennycrowe all over twitter because you and yo...   \n",
       "...                                                 ...   \n",
       "4307  another cardigan records hopscotch day party i...   \n",
       "4308  im at hempstead hair world in elmont ny httpst...   \n",
       "4309    bachelorette   laurita winery httpstcobsiifmdgz   \n",
       "4310  this job might be a great fit for you sr infor...   \n",
       "4311  im at piazzaavym in canik samsun w mertarmann ...   \n",
       "\n",
       "                                      stopwords_removed  \n",
       "0       felt first flash violence fool bumped pity fool  \n",
       "1                            ladies drink get free till  \n",
       "2           watching miranda bbc mermhart u r hilarious  \n",
       "3                          shopping kohls httptcoizkqht  \n",
       "4                 dennycrowe twitter friends cant stick  \n",
       "...                                                 ...  \n",
       "4307  another cardigan records hopscotch day party b...  \n",
       "4308  im hempstead hair world elmont ny httpstcohvyg...  \n",
       "4309      bachelorette laurita winery httpstcobsiifmdgz  \n",
       "4310  job might great fit sr information architect s...  \n",
       "4311  im piazzaavym canik samsun w mertarmann debeab...  \n",
       "\n",
       "[4312 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words(lang_dict['en'])\n",
    "\n",
    "df_eng_clean_tweets['stopwords_removed'] = df_eng_clean_tweets['lowercase'].apply(lambda x: ' '.join([item for item in x.split() if item not in stop_words]))\n",
    "df_eng_clean_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da918c6",
   "metadata": {},
   "source": [
    "I will be using Lemmatizer instead of Stemmer because Stemmer could lead to mispelled words and this will cause duplicated tokens for a supposedly same word. However, I don't think this is scalable as we increase the scope of the languages as there might not be Lemmatizer / good Lemmatizers for specific languages. That introduces the need for language specific preprocessing.\n",
    "\n",
    "Considerations:\n",
    "1. Speed - while Lemmatizer is usually slower than Stemmer, it does a better job in getting the actual word / meaning of the tokens. So here is a tradeoff introduced.\n",
    "2. Preprocess all the data source fairly - I want to create a pipeline to preprocess all languages the same way. For this assignment purpose, the SpaCy Lemmatizer used supports all three languages just fine. However, when it comes to scaling to other languages, we need to consider preprocessing each language differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0f502ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl (13.6 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13.6 MB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /opt/homebrew/lib/python3.9/site-packages (from en-core-web-sm==3.1.0) (3.1.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/homebrew/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.62.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/homebrew/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/homebrew/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.4.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/homebrew/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /opt/homebrew/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/homebrew/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/homebrew/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/homebrew/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.22.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in /opt/homebrew/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.10)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.1)\n",
      "Requirement already satisfied: setuptools in /Users/bingyuyap/Library/Python/3.9/lib/python/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (57.0.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/homebrew/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.20.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/homebrew/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/homebrew/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/homebrew/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.7.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (20.9)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /opt/homebrew/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/homebrew/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/homebrew/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /opt/homebrew/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.10.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/bingyuyap/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2020.12.5)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/homebrew/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/homebrew/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/homebrew/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.25.11)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/homebrew/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.9/site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.1.0\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/opt/homebrew/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7928f4b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweets</th>\n",
       "      <th>lowercase</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>TheOnlySarahh yall did great tonight</td>\n",
       "      <td>theonlysarahh yall did great tonight</td>\n",
       "      <td>theonlysarahh yall great tonight</td>\n",
       "      <td>theonlysarahh y all great tonight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3885</th>\n",
       "      <td>Retail Job in SanCarlos CA store manager  San ...</td>\n",
       "      <td>retail job in sancarlos ca store manager  san ...</td>\n",
       "      <td>retail job sancarlos ca store manager san carl...</td>\n",
       "      <td>retail job sancarlo ca store manager san carlo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>raeboze ImVeryIndian kenziehoneybutt best nigh...</td>\n",
       "      <td>raeboze imveryindian kenziehoneybutt best nigh...</td>\n",
       "      <td>raeboze imveryindian kenziehoneybutt best nigh...</td>\n",
       "      <td>raeboze imveryindian kenziehoneybutt good nigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Football talk with the boys gtgtgtgtgt</td>\n",
       "      <td>football talk with the boys gtgtgtgtgt</td>\n",
       "      <td>football talk boys gtgtgtgtgt</td>\n",
       "      <td>football talk boy gtgtgtgtgt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3033</th>\n",
       "      <td>Melbourne Demons Training  Victory as well  Go...</td>\n",
       "      <td>melbourne demons training  victory as well  go...</td>\n",
       "      <td>melbourne demons training victory well goschs ...</td>\n",
       "      <td>melbourne demon train victory well goschs padd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           clean_tweets  \\\n",
       "778                TheOnlySarahh yall did great tonight   \n",
       "3885  Retail Job in SanCarlos CA store manager  San ...   \n",
       "2107  raeboze ImVeryIndian kenziehoneybutt best nigh...   \n",
       "497              Football talk with the boys gtgtgtgtgt   \n",
       "3033  Melbourne Demons Training  Victory as well  Go...   \n",
       "\n",
       "                                              lowercase  \\\n",
       "778                theonlysarahh yall did great tonight   \n",
       "3885  retail job in sancarlos ca store manager  san ...   \n",
       "2107  raeboze imveryindian kenziehoneybutt best nigh...   \n",
       "497              football talk with the boys gtgtgtgtgt   \n",
       "3033  melbourne demons training  victory as well  go...   \n",
       "\n",
       "                                      stopwords_removed  \\\n",
       "778                    theonlysarahh yall great tonight   \n",
       "3885  retail job sancarlos ca store manager san carl...   \n",
       "2107  raeboze imveryindian kenziehoneybutt best nigh...   \n",
       "497                       football talk boys gtgtgtgtgt   \n",
       "3033  melbourne demons training victory well goschs ...   \n",
       "\n",
       "                                             lemmatized  \n",
       "778                   theonlysarahh y all great tonight  \n",
       "3885  retail job sancarlo ca store manager san carlo...  \n",
       "2107  raeboze imveryindian kenziehoneybutt good nigh...  \n",
       "497                        football talk boy gtgtgtgtgt  \n",
       "3033  melbourne demon train victory well goschs padd...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install spacy\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "df_eng_clean_tweets['lemmatized'] = df_eng_clean_tweets['stopwords_removed'].apply(lambda x: \" \".join([token.lemma_ for token in nlp(x)]))\n",
    "df_eng_clean_tweets.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46aa4593",
   "metadata": {},
   "source": [
    "After we lemmatized the tweets, we can now vectorize the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60ede3aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-4b93bb828c39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Use tf-idf features for NMF & SVD.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "n_features = 1000\n",
    "\n",
    "# Use tf-idf features for NMF & SVD.\n",
    "print(\"Extracting tf-idf features for NMF...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=5, max_features=n_features, stop_words='english', smooth_idf=True)\n",
    "tfidf = tfidf_vectorizer.fit_transform(df_eng_clean_tweets['lemmatized'])\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# Use tf (raw term count) features for LDA.\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=5,  max_features=n_features, stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(df_eng_clean_tweets['lemmatized'])\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "print(tfidf.shape) # check shape of the document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d86ca05b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-47-e6eaded1ce3b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-47-e6eaded1ce3b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install --no-cache --no-binary :all: --no-use-pep517 scipy\"==1.7.1\"\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install --no-cache --no-binary :all: --no-use-pep517 scipy\"==1.7.1\"\n",
    "pip install --no-use-pep517 scikit-learn\"==0.24.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67692bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
